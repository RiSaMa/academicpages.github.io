---
title: "Scene Privacy Protection"
collection: publications
permalink: /publication/2019_ICASSP
excerpt: 'This paper proposes a method to protect users sensitive information from undesired automatic inferences by service providers withouth compromising the utility of the information.'
date: 2019-05-12
venue: 'Proc. of IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), Brighton, UK, May 12-17'
#paperurl: 'http://bit.ly/2019_ICASSP_paper'
citation: 'C.Y. Li, A.S. Shamsabadi, R. Sanchez-Matilla, R. Mazzon and A. Cavallaro. &quot;Scene Privacy Protection.&quot; <i>Proc. of IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</i>.'
---
**Abstract**
Images shared on social media are routinely analysed by classifiers for content annotation and user profiling. These automatic inferences reveal to the service provider sensitive information that a naive user might want to keep private. To address this problem, we present a method designed to distort the image data so as to hinder the inference of a classifier without affecting the utility for social media users. The proposed approach is based on the Fast Gradient Sign Method~(FGSM) and limits the likelihood that automatic inference can expose the true class of a distorted image. Experimental results on a scene classification task show that the proposed  method, \emph{private} FGSM, achieves a desirable trade-off between the drop in classification accuracy  and the distortion on the private classes of the Places365-Standard dataset using ResNet50. The classifier is misled 94.40\% of the times in the top-5 classes with only a small average reduction of three image quality measures (SSIM, PSNR, BRISQUE).

**Sample image**
![Sample image](https://risama.github.io/files/2019_ICASSP/sample1.png)

**Links**
[Paper](http://bit.ly/2019_ICASSP_paper)
[Poster](http://bit.ly/2019_ICASSP_poster)